{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6ef2c1",
   "metadata": {},
   "source": [
    "# Causal Inference with Real TLC Traffic Data\n",
    "\n",
    "This notebook integrates actual taxi pickup volumes from TLC as a traffic proxy, replacing the synthetic `Traffic_Proxy` with real `traffic_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ae6771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dowhy import CausalModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d67ad3",
   "metadata": {},
   "source": [
    "## 1. Load Full Panel and TLC Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5640c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full H3 panel...\n",
      "Panel shape: (38871480, 14)\n",
      "Columns: ['h3_index', 'date', 'hour', 'accidents_count', 'accident_indicator', 'day_of_week', 'is_weekend', 'month', 'is_rush_hour', 'Traffic_Proxy', 'Baseline_Risk', 'rain_flag', 'precipitation', 'datetime']\n",
      "\n",
      "Loading TLC traffic data...\n",
      "Traffic shape: (11619229, 3)\n",
      "Traffic date range: 2022-01-01 01:00:00 to 2025-11-01 00:00:00\n",
      "Unique H3 cells: 1070\n"
     ]
    }
   ],
   "source": [
    "# Load full panel\n",
    "print(\"Loading full H3 panel...\")\n",
    "panel = pd.read_csv('../data/h3_full_panel_res8.csv')\n",
    "panel['date'] = pd.to_datetime(panel['date'])\n",
    "panel['datetime'] = panel['date'] + pd.to_timedelta(panel['hour'], unit='h')\n",
    "\n",
    "print(f\"Panel shape: {panel.shape}\")\n",
    "print(f\"Columns: {panel.columns.tolist()}\")\n",
    "\n",
    "# Load TLC traffic\n",
    "print(\"\\nLoading TLC traffic data...\")\n",
    "traffic = pd.read_parquet('../data/traffic_h3_2022_2025_polyfill.parquet')\n",
    "traffic['match_hour'] = pd.to_datetime(traffic['match_hour'])\n",
    "\n",
    "print(f\"Traffic shape: {traffic.shape}\")\n",
    "print(f\"Traffic date range: {traffic['match_hour'].min()} to {traffic['match_hour'].max()}\")\n",
    "print(f\"Unique H3 cells: {traffic['h3_index'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e574e8a",
   "metadata": {},
   "source": [
    "## 2. Merge Traffic Data into Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecee795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging traffic data...\n",
      "✓ Merged shape: (38871480, 16)\n",
      "Traffic coverage: 10,796,648 / 38,871,480 (27.78%)\n",
      "\n",
      "Traffic statistics:\n",
      "count    3.887148e+07\n",
      "mean     3.197427e+00\n",
      "std      2.120617e+01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      1.428571e-01\n",
      "max      1.239000e+03\n",
      "Name: traffic_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Merge traffic onto panel\n",
    "print(\"Merging traffic data...\")\n",
    "df = panel.merge(\n",
    "    traffic[['h3_index', 'match_hour', 'traffic_count']], \n",
    "    left_on=['h3_index', 'datetime'], \n",
    "    right_on=['h3_index', 'match_hour'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing traffic with 0 (no pickups)\n",
    "df['traffic_count'] = df['traffic_count'].fillna(0)\n",
    "\n",
    "print(f\"✓ Merged shape: {df.shape}\")\n",
    "print(f\"Traffic coverage: {(df['traffic_count'] > 0).sum():,} / {len(df):,} ({(df['traffic_count'] > 0).mean()*100:.2f}%)\")\n",
    "\n",
    "# Drop old Traffic_Proxy and match_hour columns\n",
    "df.drop(columns=['Traffic_Proxy', 'match_hour'], inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"\\nTraffic statistics:\")\n",
    "print(df['traffic_count'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e3c1a",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for DoWhy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329170f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in analysis variables:\n",
      "accident_indicator       0\n",
      "accidents_count          0\n",
      "rain_flag                0\n",
      "day_of_week              0\n",
      "is_weekend               0\n",
      "month                    0\n",
      "is_rush_hour             0\n",
      "Baseline_Risk         1135\n",
      "traffic_count            0\n",
      "dtype: int64\n",
      "\n",
      "Rows after dropping missing values: 38,870,345 (retained 100.00%)\n",
      "\n",
      "Class balance:\n",
      "  Rain hours: 4,182,475 (10.76%)\n",
      "  Accident hours: 334,796 (0.86%)\n",
      "  Hours with traffic: 10,796,648 (27.78%)\n",
      "\n",
      "Cross-tabulation (Rain vs Accident):\n",
      "accident_indicator         0         1\n",
      "rain_flag                             \n",
      "0                   0.991481  0.008519\n",
      "1                   0.990605  0.009395\n",
      "All                 0.991387  0.008613\n"
     ]
    }
   ],
   "source": [
    "# Select analysis variables (replace Traffic_Proxy with traffic_count)\n",
    "analysis_vars = ['accident_indicator', 'accidents_count', 'rain_flag', 'day_of_week', 'is_weekend', \n",
    "                 'month', 'is_rush_hour', 'Baseline_Risk', 'traffic_count']\n",
    "\n",
    "print(\"Missing values in analysis variables:\")\n",
    "print(df[analysis_vars].isnull().sum())\n",
    "\n",
    "# Drop rows with missing Baseline_Risk\n",
    "df_clean = df[analysis_vars].dropna().copy()\n",
    "\n",
    "# Ensure binary types\n",
    "df_clean['accident_indicator'] = df_clean['accident_indicator'].astype(int)\n",
    "df_clean['rain_flag'] = df_clean['rain_flag'].astype(int)\n",
    "\n",
    "print(f\"\\nRows after dropping missing values: {len(df_clean):,} (retained {len(df_clean)/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Class balance\n",
    "print(f\"\\nClass balance:\")\n",
    "print(f\"  Rain hours: {df_clean['rain_flag'].sum():,} ({df_clean['rain_flag'].mean()*100:.2f}%)\")\n",
    "print(f\"  Accident hours: {df_clean['accident_indicator'].sum():,} ({df_clean['accident_indicator'].mean()*100:.2f}%)\")\n",
    "print(f\"  Hours with traffic: {(df_clean['traffic_count'] > 0).sum():,} ({(df_clean['traffic_count'] > 0).mean()*100:.2f}%)\")\n",
    "\n",
    "# Cross-tabulation: rain vs accident\n",
    "print(f\"\\nCross-tabulation (Rain vs Accident):\")\n",
    "crosstab = pd.crosstab(df_clean['rain_flag'], df_clean['accident_indicator'], \n",
    "                       margins=True, normalize='index')\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85160ee",
   "metadata": {},
   "source": [
    "## 4. Define Causal DAG with Real Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae3b75f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Causal DAG defined with real traffic_count\n",
      "\n",
      "DAG structure:\n",
      "  Confounders → Rain\n",
      "  Confounders → Traffic (actual TLC pickups)\n",
      "  Confounders → Accident Indicator\n",
      "  Rain → Accident Indicator (causal effect of interest)\n"
     ]
    }
   ],
   "source": [
    "# Updated DAG with traffic_count\n",
    "causal_graph = \"\"\"\n",
    "digraph {\n",
    "    day_of_week -> rain_flag;\n",
    "    day_of_week -> traffic_count;\n",
    "    day_of_week -> accident_indicator;\n",
    "    \n",
    "    is_weekend -> rain_flag;\n",
    "    is_weekend -> traffic_count;\n",
    "    is_weekend -> accident_indicator;\n",
    "    \n",
    "    month -> rain_flag;\n",
    "    month -> accident_indicator;\n",
    "    \n",
    "    is_rush_hour -> traffic_count;\n",
    "    is_rush_hour -> accident_indicator;\n",
    "    \n",
    "    Baseline_Risk -> accident_indicator;\n",
    "    traffic_count -> accident_indicator;\n",
    "    \n",
    "    rain_flag -> accident_indicator;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"✓ Causal DAG defined with real traffic_count\")\n",
    "print(\"\\nDAG structure:\")\n",
    "print(\"  Confounders → Rain\")\n",
    "print(\"  Confounders → Traffic (actual TLC pickups)\")\n",
    "print(\"  Confounders → Accident Indicator\")\n",
    "print(\"  Rain → Accident Indicator (causal effect of interest)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f706a2c",
   "metadata": {},
   "source": [
    "## 5. Initialize DoWhy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee6c2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DoWhy causal model...\n",
      "\n",
      "✓ Causal model initialized\n",
      "  Treatment: rain_flag\n",
      "  Outcome: accident_indicator\n",
      "  Confounders: day_of_week, is_weekend, month, is_rush_hour, Baseline_Risk, traffic_count (TLC actual)\n"
     ]
    }
   ],
   "source": [
    "# Initialize causal model with traffic_count\n",
    "print(\"Initializing DoWhy causal model...\")\n",
    "\n",
    "model = CausalModel(\n",
    "    data=df_clean,\n",
    "    treatment='rain_flag',\n",
    "    outcome='accident_indicator',\n",
    "    graph=causal_graph,\n",
    "    common_causes=['day_of_week', 'is_weekend', 'month', 'is_rush_hour', \n",
    "                   'Baseline_Risk', 'traffic_count']\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Causal model initialized\")\n",
    "print(f\"  Treatment: rain_flag\")\n",
    "print(f\"  Outcome: accident_indicator\")\n",
    "print(f\"  Confounders: day_of_week, is_weekend, month, is_rush_hour, Baseline_Risk, traffic_count (TLC actual)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bab9dbd",
   "metadata": {},
   "source": [
    "## 6. Identify Causal Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c459640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying causal estimand...\n",
      "\n",
      "============================================================\n",
      "IDENTIFIED ESTIMAND\n",
      "============================================================\n",
      "Estimand type: EstimandType.NONPARAMETRIC_ATE\n",
      "\n",
      "### Estimand : 1\n",
      "Estimand name: backdoor\n",
      "Estimand expression:\n",
      "     d                                                          \n",
      "────────────(E[accident_indicator|day_of_week,month,is_weekend])\n",
      "d[rain_flag]                                                    \n",
      "Estimand assumption 1, Unconfoundedness: If U→{rain_flag} and U→accident_indicator then P(accident_indicator|rain_flag,day_of_week,month,is_weekend,U) = P(accident_indicator|rain_flag,day_of_week,month,is_weekend)\n",
      "\n",
      "### Estimand : 2\n",
      "Estimand name: iv\n",
      "No such variable(s) found!\n",
      "\n",
      "### Estimand : 3\n",
      "Estimand name: frontdoor\n",
      "No such variable(s) found!\n",
      "\n",
      "### Estimand : 4\n",
      "Estimand name: general_adjustment\n",
      "Estimand expression:\n",
      "     d                                                          \n",
      "────────────(E[accident_indicator|month,is_weekend,day_of_week])\n",
      "d[rain_flag]                                                    \n",
      "Estimand assumption 1, Unconfoundedness: If U→{rain_flag} and U→accident_indicator then P(accident_indicator|rain_flag,month,is_weekend,day_of_week,U) = P(accident_indicator|rain_flag,month,is_weekend,day_of_week)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify estimand\n",
    "print(\"Identifying causal estimand...\")\n",
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IDENTIFIED ESTIMAND\")\n",
    "print(\"=\"*60)\n",
    "print(identified_estimand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9905278",
   "metadata": {},
   "source": [
    "## 7. Estimate ATE with Propensity Score Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e4432a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating causal effect using Propensity Score Weighting...\n",
      "\n",
      "============================================================\n",
      "CAUSAL EFFECT ESTIMATE (ATE)\n",
      "============================================================\n",
      "Treatment: Rain (rain_flag = 1)\n",
      "Outcome: Accident Indicator (binary)\n",
      "Method: Propensity Score Weighting\n",
      "Confounders: Now includes REAL TLC traffic volume\n",
      "\n",
      "Average Treatment Effect (ATE): 0.000913\n",
      "\n",
      "Interpretation:\n",
      "  Rain INCREASES probability of any crash by 0.0913 percentage points.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Estimate using propensity score weighting\n",
    "print(\"Estimating causal effect using Propensity Score Weighting...\")\n",
    "\n",
    "estimate = model.estimate_effect(\n",
    "    identified_estimand,\n",
    "    method_name=\"backdoor.propensity_score_weighting\",\n",
    "    target_units=\"ate\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CAUSAL EFFECT ESTIMATE (ATE)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Treatment: Rain (rain_flag = 1)\")\n",
    "print(f\"Outcome: Accident Indicator (binary)\")\n",
    "print(f\"Method: Propensity Score Weighting\")\n",
    "print(f\"Confounders: Now includes REAL TLC traffic volume\")\n",
    "\n",
    "print(f\"\\nAverage Treatment Effect (ATE): {estimate.value:.6f}\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "if estimate.value > 0:\n",
    "    print(f\"  Rain INCREASES probability of any crash by {estimate.value*100:.4f} percentage points.\")\n",
    "elif estimate.value < 0:\n",
    "    print(f\"  Rain DECREASES probability of any crash by {abs(estimate.value)*100:.4f} percentage points.\")\n",
    "else:\n",
    "    print(f\"  Rain has NO EFFECT on probability of any crash.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29417b5",
   "metadata": {},
   "source": [
    "## 8. Compare Results: Proxy vs Real Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "291d77b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "COMPARISON: TRAFFIC PROXY vs REAL TLC DATA\n",
      "############################################################\n",
      "\n",
      "Previous (Traffic_Proxy):  ATE = 0.000913 (0.0913 pp)\n",
      "Current  (TLC traffic_count): ATE = 0.000913 (0.0913 pp)\n",
      "\n",
      "Difference: -0.000000 (-0.05% change)\n",
      "→ Results are CONSISTENT - proxy was a good approximation\n",
      "############################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"COMPARISON: TRAFFIC PROXY vs REAL TLC DATA\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "# Previous result from 04_causal_inference.ipynb\n",
    "ate_with_proxy = 0.000913\n",
    "\n",
    "print(f\"\\nPrevious (Traffic_Proxy):  ATE = {ate_with_proxy:.6f} ({ate_with_proxy*100:.4f} pp)\")\n",
    "print(f\"Current  (TLC traffic_count): ATE = {estimate.value:.6f} ({estimate.value*100:.4f} pp)\")\n",
    "\n",
    "diff = estimate.value - ate_with_proxy\n",
    "pct_change = (diff / ate_with_proxy) * 100 if ate_with_proxy != 0 else 0\n",
    "\n",
    "print(f\"\\nDifference: {diff:.6f} ({pct_change:+.2f}% change)\")\n",
    "\n",
    "if abs(pct_change) < 5:\n",
    "    print(\"\\u2192 Results are CONSISTENT - proxy was a good approximation\")\n",
    "elif abs(pct_change) < 20:\n",
    "    print(\"\\u2192 Results are SIMILAR - real traffic provides refinement\")\n",
    "else:\n",
    "    print(\"\\u2192 Results DIFFER substantially - real traffic reveals new dynamics\")\n",
    "\n",
    "print(\"#\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
